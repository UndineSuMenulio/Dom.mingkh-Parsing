{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добро пожаловать!\n",
    "\n",
    "Этот блокнот предназначен для парсинга и обработки информации с сайта **[dom.mingkh.ru](https://dom.mingkh.ru/)**. \n",
    "\n",
    "Сбор проводится **по отдельным городам** (не по целым регионам).\n",
    "\n",
    "Впоследствии подготовленные данные геокодировать (= присвоить координаты) адреса двумя вариантами:\n",
    "\n",
    "* с помощью API МинЖКХ;\n",
    "* с помощью встроенной функции «Пакетный геокодер Nominatim» в QGIS. Проверить корректность написания адреса можно на сайте [Nominatim OpenStreetMap](https://nominatim.openstreetmap.org/ui/search.html).\n",
    "\n",
    "**Внимание!** В базу МинЖКХ занесены далеко не все здания. Особенно редко учитываются частные постройки.\n",
    "\n",
    "**Содержание блокнота**:\n",
    "1. Импортируем библиотеки.\n",
    "2. Инициализируем функцию.\n",
    "3. Узнаём число домов в городе или регионе.\n",
    "4. Собираем данные.\n",
    "5. Дособираем данные.\n",
    "6. Указываем координаты с помощью API.\n",
    "7. Подготавливаем адреса для геокодирования в QGIS.\n",
    "8. Скачиваем получившиеся данные.\n",
    "\n",
    "**Москва** как субъект федерации ≠ Москва в базе МинЖКХ. Эксклавы и округа Новой Москвы указаны отдельно. Потому в url для старой Москвы название региона и название самого города дублируется: https://dom.mingkh.ru/moskva/moskva/houses\n",
    "\n",
    "Относитесь к данным **скептически** в хорошем смысле слова, не доверяйте им на 100 %. Так, в Москве вы можете найти дом 1703 года на Аминьевском шоссе — очевидно, что это просто чья-то опечатка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 1. Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 1. Импортируем нужные библиотеки\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import winsound\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import randint\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 2. Инициализируем функцию\n",
    "\n",
    "Нам нужна функция, которая пройдёт по веб-таблице со всеми жилыми домами города N, соберёт ссылки на страницы с детальной информацией про дома и вернёт датафрейм с подробной информацией.\n",
    "\n",
    "В приведённой ниже функции мы собираем:\n",
    "\n",
    "    1. Номер (порядковый в системе dom.mingkh для конкретного населённого пункта). \n",
    "    2. Адрес (дома).\n",
    "    3. Ссылка (на детальное описание дома). \n",
    "    4. Площадь всего (жилые, нежилые помещения и общее имущество). \n",
    "    5. Год постройки (дома).\n",
    "    6. Число этажей.\n",
    "    7. Аварийный (ли дом, ответы «да» или «нет»).\n",
    "    8. Состояние дома (исправный или аварийный).\n",
    "    9. Количество квартир (в доме).\n",
    "    10. Тип дома («многоквартирный дом» или нечто иное).\n",
    "    11. Площадь жилых (помещений) в м2.\n",
    "    12. Площадь нежилых (помещений) в м2. \n",
    "    13. Культурное наследие (является ли дом объектом культурного наследия).\n",
    "    \n",
    "Однако на страницах домов содержится больше информации — вы можете добавить её вручную, самостоятельно поработав с кодом по нашему примеру.\n",
    "\n",
    "Примеры страниц для сбора: \n",
    "\n",
    "* [таблица всех жилых домов Москвы](https://dom.mingkh.ru/moskva/moskva/houses), \n",
    "* [подробные данные о конкретном доме](https://dom.mingkh.ru/moskva/moskva/716860).\n",
    "\n",
    "**Внимание!** Чтобы код не сломался, по умолчанию числовые значения сохраняются как текст. Бывает, что в исходный данных вместо года указан прочерк —, например. Разные города, по всей видимости, заполнялись разными людьми, и предугадать все варианты сложно. Потому после сбора данных и перед этапом анализа всё равно необходима очистка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 2. Инициализируем нужные функции\n",
    "\n",
    "def get_a_df_from_one_page (initial_table):\n",
    "    \n",
    "    ''' Эта функция принимает на вход html-таблицу и возвращает pandas-датафрейм со собранными атрибутами. \n",
    "    Если страница дома получена успешно, но данных нет, в таблицу добавится значение \"Нет информации\". \n",
    "    Если же код по какой-то причине сработает с ошибкой, будут выведены сообщения \"Nothing to show\" и \"No data\".\n",
    "    Первая строка каждой таблицы — это заголовки столбцов, поэтому по одной ошибке на страницу — это нормально.'''\n",
    "    \n",
    "    all_rows = []\n",
    "    for every_row in initial_table.find_all ('tr'):\n",
    "        all_elements = every_row.find_all('td')\n",
    "        try:\n",
    "            number = all_elements [0].text\n",
    "            address = all_elements [2].text\n",
    "            area = all_elements [3].text\n",
    "            year = all_elements [4].text\n",
    "            levels = all_elements [5].text\n",
    "        except:\n",
    "            print ('Nothing to add')\n",
    "        \n",
    "        try:\n",
    "            link = 'https://dom.mingkh.ru' + every_row.find('a')['href']\n",
    "            house_id = int(link.split('/')[-1])\n",
    "            \n",
    "            house = soup (requests.get(link).content)\n",
    "\n",
    "            all_in_table_left = house.find_all ('table')[0].find_all ('td')\n",
    "            all_in_table_left = [i.text for i in all_in_table_left if i.text != ' ']\n",
    "            try:\n",
    "                needs_repair = all_in_table_left[all_in_table_left.index('Дом признан аварийным ')+1]\n",
    "            except:\n",
    "                needs_repair = 'Нет информации'\n",
    "            try:\n",
    "                raggedness = all_in_table_left [all_in_table_left.index('Состояние дома ')+1]\n",
    "            except:\n",
    "                raggedness = 'Нет информации'\n",
    "            try:\n",
    "                flat_number = all_in_table_left [all_in_table_left.index('Количество квартир ')+1]\n",
    "            except:\n",
    "                flat_number = 'Нет информации'\n",
    "\n",
    "\n",
    "            all_in_table_right = house.find_all ('table')[1].find_all ('td')\n",
    "            all_in_table_right = [i.text for i in all_in_table_right if i.text != ' ']\n",
    "            try:\n",
    "                house_type = all_in_table_left [all_in_table_left.index('Тип дома ')+1]\n",
    "            except:\n",
    "                house_type = 'Нет информации'\n",
    "                try:\n",
    "                    house_type = all_in_table_right [all_in_table_right.index('Тип дома ')+1]\n",
    "                except:\n",
    "                    house_type = 'Нет информации'\n",
    "            try:\n",
    "                living_area = all_in_table_right [all_in_table_right.index('Площадь жилых помещений м2 ')+1]\n",
    "            except:\n",
    "                living_area = 'Нет информации'\n",
    "            try:\n",
    "                non_living_area = all_in_table_right [all_in_table_right.index('Площадь нежилых помещений м2 ')+1]\n",
    "            except:\n",
    "                non_living_area = 'Нет информации'\n",
    "            try:\n",
    "                culture = all_in_table_right [all_in_table_right.index('Статус объекта культурного наследия ')+1]\n",
    "            except:\n",
    "                culture = 'Нет информации'\n",
    "\n",
    "            needed_in_table = [needs_repair, raggedness, flat_number, house_type, living_area, non_living_area, culture]\n",
    "\n",
    "        except:\n",
    "            print (every_row)\n",
    "            print ('Nothing to show')\n",
    "            needed_in_table = ['Нет информации', 'Нет информации', 'Нет информации', \n",
    "                               'Нет информации', 'Нет информации', 'Нет информации', 'Нет информации']\n",
    "\n",
    "        try:\n",
    "            all_rows_data = [number, address, link, house_id, area, year, levels]\n",
    "            all_rows_data.extend (needed_in_table)\n",
    "            all_rows.append (all_rows_data)\n",
    "        except:\n",
    "            print ('No data')\n",
    "    first_page = pd.DataFrame (all_rows, columns = ['Номер', 'Адрес', 'Ссылка', 'ID дома', 'Площадь всего', 'Год постройки', 'Число этажей', \n",
    "                                       'Аварийный', 'Состояние дома', 'Количество квартир', 'Тип дома', \n",
    "                                       'Площадь жилых в м2', 'Площадь нежилых в м2', 'Культурное наследие'])\n",
    "    return first_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 3. Узнаём число домов\n",
    "\n",
    "Запустите ячейку. В выпавшее поле вставьте ссылку на город в формате https://dom.mingkh.ru/bashkortostan/ufa/houses или https://dom.mingkh.ru/moskva/moskva/houses. \n",
    "\n",
    "**Проверьте ссылку**:\n",
    "1. В ссылке должен быть указан не только регион, но и непосредственно **город**. \n",
    "2. Ссылка должна оканчиваться на **слово houses** — иначе число страниц будет рассчитано неверно.\n",
    "\n",
    "В строчке под ячейкой вы увидите, сколько в этом регионе домов и сколько страниц придётся собрать.\n",
    "\n",
    "**Обязательно** запустите эту ячейку, она нужна для выполнения последующих ячеек. Перезапускайте её каждый раз, когда нужно поменять регион или город и собрать данные по новой ссылке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Шаг 3. Узнаём, как много придётся собрать\n",
    "\n",
    "def last_page_number (og_list):\n",
    "    ''' Принимает на вход список ссылок в html-тэгах, собранных через soup.find_all.\n",
    "    Возвращает номер последней страницы как int'''\n",
    "    k = [int(i['data-ci-pagination-page']) for i in og_list if i.text == 'Последняя'][0]\n",
    "    return k\n",
    "\n",
    "base_url = input ('Вставьте ссылку на нужный город или регион: ')\n",
    "region = base_url.split ('/')[3]\n",
    "try:\n",
    "    city = base_url.split ('/')[4]\n",
    "except:\n",
    "    print ('Выбран целый регион, без города')\n",
    "base_x = soup (requests.get (base_url).content)\n",
    "try:\n",
    "    last_page = last_page_number (base_x.find_all ('a'))\n",
    "    last_page_html = soup (requests.get (base_url+'?page='+str(last_page)).content)\n",
    "    house_num = int(last_page_html.find_all ('td')[-6].text)\n",
    "except IndexError:\n",
    "    last_page = 1\n",
    "    house_num = int(base_x.find_all ('td')[-6].text)\n",
    "print (f'Выборка города {city} региона {region} состоит из {last_page} страниц и {house_num} домов.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 4. Собираем данные\n",
    "\n",
    "Запускаем код для сбора данных. Обратите внимание, что если ваш компьютер заснёт, код прервёт выполнение. Стоит сохранить накопленный результат в отдельную переменную или файл, продолжить выполнение кода с достигнутой точки, а затем объединить получившиеся файлы.\n",
    "\n",
    "Для ориентира: сбор данных по Москве (32 727 домов) занимает 3 часа.\n",
    "\n",
    "Когда парсинг заканчивается, раздаётся звук."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 3. Код проходит по всем страницам веб-таблицы города и собирает данные в единую таблицу\n",
    "\n",
    "general_df = pd.DataFrame ()\n",
    "\n",
    "for i in tqdm (range (1, last_page+1)): # Правым краем диапазона ставим число страниц в таблице города + 1\n",
    "    url = f'{base_url}?page={i}' \n",
    "    x = soup (requests.get (url).content)\n",
    "    table = x.find ('table')\n",
    "    result = get_a_df_from_one_page (table)\n",
    "    general_df = general_df.append (result, ignore_index=True)\n",
    "    time.sleep (randint (0,2))\n",
    "winsound.Beep (440, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите ячейку 3.0, чтобы проверить, всё ли в порядке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 3.0 Предпросмотр получившегося датафрейма \n",
    "\n",
    "general_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если всё хорошо, можно просто сохранить получившийся датафрейм в переменную, которая будет использоваться далее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 3.1. Объединяем результаты в один датафрейм\n",
    "\n",
    "final_df = general_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если код досрочно прервал работу, сохраните результаты во временный файл. Переименуйте его, чтобы не перепутать с другими."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 3.2 Сохранение временных результатов на компьютер\n",
    "\n",
    "general_df.to_csv ('Временный.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В моём случае при сборе данных Москвы выполнение кода прерывалось дважды, поэтому мне пришлось объединить три файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 3.3. Объединяем результаты в один датафрейм\n",
    "\n",
    "df1 = pd.read_csv ('Дома 0_3150.csv').drop ('Unnamed: 0', axis=1)\n",
    "df2 = pd.read_csv ('Дома 3001_28100.csv').drop ('Unnamed: 0', axis=1)\n",
    "df3 = pd.read_csv ('Дома 28100_32727.csv').drop ('Unnamed: 0', axis=1)\n",
    "\n",
    "final_df = df1.append (df2)\n",
    "final_df = final_df.append (df3)\n",
    "final_df = final_df.drop_duplicates()\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 5. Дособираем данные\n",
    "\n",
    "У некоторых домов было очень мало информации, поэтому код вернул «Нет информации», хотя она просто была организована иным образом. Также «Нет информации» возвращалось в результате прервавшегося выполнения кода. Чтобы дособрать нужные данные, выделим ссылки на все «несобранные» дома и пройдёмся по ним отдельно.\n",
    "\n",
    "Если Шаг 5.1 вернул пустой список, вы можете пропустить весь этот шаг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 5.1. Выделяем ссылки на дома без информации\n",
    "\n",
    "all_links_no_info = list (final_df[final_df ['Тип дома']=='Нет информации']['Ссылка'])\n",
    "print (f'Нужно добрать {len (all_links_no_info)} домов')\n",
    "all_links_no_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 5.2. Прописываем функцию для сбора данных по домам без информации\n",
    "\n",
    "def get_a_df_from_one_page_no_info (link):\n",
    "    \n",
    "    ''' Функция принимает на вход ссылку на конкретный дом и возвращает в виде датафрейма всего пять основных параметров:\n",
    "    1. Ссылка на дом\n",
    "    2. Признан ли дом аварийным\n",
    "    3. Состояние дома\n",
    "    4. Тип дома\n",
    "    5. Количество квартир\n",
    "    Остальные поля заполняются как «Нет информации».'''\n",
    "    \n",
    "    all_rows = []\n",
    "    try:\n",
    "        house = soup (requests.get(link).content)\n",
    "\n",
    "        all_in_table_left = house.find_all ('table')[0].find_all ('td')\n",
    "        all_in_table_left = [i.text for i in all_in_table_left if i.text != ' ']\n",
    "        try:\n",
    "            needs_repair = all_in_table_left[all_in_table_left.index('Дом признан аварийным ')+1]\n",
    "        except:\n",
    "            needs_repair = 'Нет информации'\n",
    "        try:\n",
    "            raggedness = all_in_table_left [all_in_table_left.index('Состояние дома ')+1]\n",
    "        except:\n",
    "            raggedness = 'Нет информации'\n",
    "        try:\n",
    "            house_type = all_in_table_left [all_in_table_left.index('Тип дома ')+1]\n",
    "        except:\n",
    "            house_type = 'Нет информации'\n",
    "        try:\n",
    "            flat_number = all_in_table_left [all_in_table_left.index('Количество квартир ')+1]\n",
    "        except:\n",
    "            flat_number = 'Нет информации'\n",
    "            \n",
    "\n",
    "        needed_in_table = [link, needs_repair, raggedness, flat_number, house_type, 'Нет информации', 'Нет информации', 'Нет информации']\n",
    "\n",
    "    except:\n",
    "        print ('Nothing to show')\n",
    "        needed_in_table = ['Нет информации', 'Нет информации', 'Нет информации', \n",
    "                           'Нет информации', 'Нет информации', 'Нет информации', 'Нет информации']\n",
    "\n",
    "    try:\n",
    "        all_rows.append (needed_in_table)\n",
    "    except:\n",
    "        print ('No data')\n",
    "    first_page = pd.DataFrame (all_rows, columns = ['Ссылка', 'Аварийный', 'Состояние дома', 'Количество квартир', 'Тип дома', \n",
    "                                       'Площадь жилых в м2', 'Площадь нежилых в м2', 'Культурное наследие'])\n",
    "    return first_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 5.3. Проходимся по ссылкам всех домов без информации и собираем данные об их аварийности и типе здания\n",
    "\n",
    "key = pd.DataFrame (columns = ['Ссылка', 'Аварийный', 'Состояние дома', 'Количество квартир', 'Тип дома', \n",
    "                                       'Площадь жилых в м2', 'Площадь нежилых в м2', 'Культурное наследие'])\n",
    "for i in tqdm (all_links_no_info):\n",
    "    may = get_a_df_from_one_page_no_info (i)\n",
    "    key = key.append (may)\n",
    "    time.sleep (randint (0,2))\n",
    "\n",
    "winsound.Beep (440, 1000)\n",
    "key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оказалось, что почти все дособранные здания обладают одинаковыми характеристиками: неаварийные, исправные многоквартирные дома. Поэтому мы просто заменяем значения в исходном датафрейме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 5.4. Заменяем значения\n",
    "\n",
    "final_df.loc[final_df['Ссылка'].isin(all_links_no_info), 'Аварийный'] = 'Нет'\n",
    "final_df.loc[final_df['Ссылка'].isin(all_links_no_info), 'Состояние дома'] = 'Исправный'\n",
    "final_df.loc[final_df['Ссылка'].isin(all_links_no_info), 'Тип дома'] = 'Многоквартирный дом'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё раз проверяем датафрейм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 5.5. Проверка данных\n",
    "\n",
    "all_links_no_info_2 = list (final_df[final_df ['Тип дома']=='Нет информации']['Ссылка'])\n",
    "print (f'Нужно добрать {len (all_links_no_info_2)} домов')\n",
    "print (all_links_no_info)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если какая-то ссылка всё-таки обработалась некорректно, заменяем данные вручную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 5.6. Заменяем значения для ссылки-исключения\n",
    "\n",
    "final_df.loc [final_df['Ссылка'] == 'https://dom.mingkh.ru/moskva/moskva/716860','Площадь жилых в м2'] = 5487\n",
    "final_df.loc [final_df['Ссылка'] == 'https://dom.mingkh.ru/moskva/moskva/716860','Площадь нежилых в м2'] = 2089\n",
    "final_df.loc [final_df['Ссылка'] == 'https://dom.mingkh.ru/moskva/moskva/716860','Культурное наследие'] = 'Нет'\n",
    "final_df.loc [final_df['Ссылка'] == 'https://dom.mingkh.ru/moskva/moskva/716860','Количество квартир'] = 108\n",
    "final_df.loc [final_df['Ссылка'] == 'https://dom.mingkh.ru/moskva/moskva/716860']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 6. Собираем координаты с помощью API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберём координаты с помощью API МинЖКХ. Несмотря на официальную поддержку, этот метод не гарантирует 100 % геокодирования: координаты не всех домов есть в базе. Так, для г. Кумертау не распознано 11 домов из 358 (3 %), а в г. Белорецке — 35 из 370 (9,5 %). В Москве не распознано 435 домов из 32 727, и минимум 7 распознано неверно, итого ошибка — 1,35 %.\n",
    "\n",
    "Если в базе нет координат дома, в датасет вносятся координаты [0,0]. Это точка в Атлантическом океане, недалеко от Африки.\n",
    "\n",
    "Когда парсинг заканчивается, раздаётся звук."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Шаг 6.1. Добавляем в наш датасет координаты домов\n",
    "\n",
    "print (f'Начало работы кода: {time.strftime(\"%H:%M:%S\", time.localtime())}')\n",
    "\n",
    "headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/118.0\",\n",
    "        \"Accept-Language\": \"ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "    }\n",
    "\n",
    "def get_coordinates (house_id):\n",
    "    \n",
    "    ''' Функция принимает на вход уникальный идентификатор дома (int) и возвращает список координат (широта, долгота). '''\n",
    "    try:\n",
    "        x = requests.get (f'https://dom.mingkh.ru/api/map/house/{house_id}', headers = headers)\n",
    "        z = x.json()\n",
    "        coordinates = z['features'][0]['geometry']['coordinates']\n",
    "        print ('Есть координаты')\n",
    "    except:\n",
    "        print ('Нет координат')\n",
    "        coordinates = [0,0]\n",
    "    time.sleep (randint (0,1))\n",
    "    return (coordinates)\n",
    "\n",
    "final_df ['Координаты'] = final_df['ID дома'].apply (lambda x: get_coordinates(x))\n",
    "winsound.Beep (440, 1000)\n",
    "final_df ['Latitude'] = final_df ['Координаты'].apply (lambda x: x[0])\n",
    "final_df ['Longitude'] = final_df ['Координаты'].apply (lambda x: x[1])\n",
    "\n",
    "print (f'Конец работы кода: {time.strftime(\"%H:%M:%S\", time.localtime())}')\n",
    "print ('Код завершил работу. Проверьте датафрейм')\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 7. Подготавливаем адреса для геокодирования в QGIS\n",
    "\n",
    "Этот шаг нужен, если API МинЖКХ не справился или вы по какой-то причине не хотите им пользоваться.\n",
    "\n",
    "Nominatim OSM распознаёт адреса только в определённом формате, поэтому перед загрузкой в QGIS нам нужно переформатировать адреса с помощью регулярных выражений.\n",
    "\n",
    "Так, система не понимает «проезд 1-й Тушинский, 3», но понимает «1-й Тушинский проезд, 3».\n",
    "\n",
    "Адреса с порядковыми номерами и определениями «Малая(ый)/Большая(ой)» унифицировать сложнее. Здесь нужен более сложный алгоритм  с условием «если не найдёшь в Nominatim этот вариант, переделай его по такой схеме».  \n",
    "\n",
    "Так, в базе дом.минжкх следующие адреса записаны одинаково:\n",
    "* ул. 1-я Ватутинская, 5\n",
    "* ул. 1-я Машиностроения, 4\n",
    "\n",
    "Однако в базе Nominatim OSM они записаны по-разному:\n",
    "* 1-я Ватутинская ул., 5\n",
    "* 1-я ул. Машиностроения, 4 к1\n",
    "\n",
    "Поэтому текущий алгоритм унификации обречён спасать одни адреса и терять другие, потому нуждается в дальнейшей оптимизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 7. Унифицируем адреса\n",
    "\n",
    "import re\n",
    "final_df ['Адрес'] = final_df ['Адрес'].str.replace ('корпус ', 'к')\n",
    "final_df ['Адрес'] = final_df ['Адрес'].str.replace ('строение ', 'с')\n",
    "final_df ['Адрес'] = final_df ['Адрес'].str.replace ('Строение ', 'с')\n",
    "final_df ['Адрес'] = final_df ['Адрес'].str.replace ('кв-л', 'квартал')\n",
    "final_df ['Адрес'] = final_df ['Адрес'].str.replace ('пр-д', 'проезд')\n",
    "final_df ['Адрес'] = final_df ['Адрес'].replace (r'^п\\. .*, ул\\. (.*),(.*)', r'\\1 ул.,\\2', regex=True)\n",
    "final_df ['Адрес'] = final_df ['Адрес'].replace (r'^п\\. (.*?), (.*)', r'\\2', regex=True)\n",
    "final_df ['Адрес'] = final_df ['Адрес'].replace (r'^ул\\. (.*),(.*)', r'\\1 ул.,\\2', regex=True)\n",
    "final_df ['Адрес'] = final_df ['Адрес'].replace (r'^проезд,?\\.? (.*),(.*)', r'\\1 проезд,\\2', regex=True)\n",
    "final_df ['Адрес'] = final_df ['Адрес'].replace (r'^пер\\.,?\\.? (.*),(.*)', r'\\1 пер,\\2', regex=True)\n",
    "final_df ['Адрес'] = final_df ['Адрес'].str.replace ('пер\\.', 'пер')\n",
    "final_df ['Адрес'] = final_df ['Адрес'].str.replace ('б-р', 'бульвар')\n",
    "final_df ['Адрес'] = final_df ['Адрес'].str.replace ('пр-кт', 'проспект')\n",
    "final_df ['Адрес'] = final_df ['Адрес'].replace (r'^туп\\.,?\\.? (.*),(.*)', r'\\1 туп,\\2', regex=True)\n",
    "final_df ['Адрес'] = final_df ['Адрес'].replace (r'^ш\\.,?\\.? (.*),(.*)', r'\\1 ш,\\2', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для пакетного геокодирования вам понадобится современная версия QGIS. У меня стоит 3.30.1-'s-Hertogenbosch. Вам нужно зайти в шестерёнку на панели инструментов и найти «Пакетный геокодер Nominatim».\n",
    "\n",
    "Тем не менее, даже со всеми этапами препроцессинга, алгоритм не распознал или распознал некорректно 22 % адресов. Это вызвано в том числе тем, что в Советском Союзе улицы называли одинаково, так что «Ирония судьбы» актуальна  даже в геоаналитике. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шаг 8. Скачиваем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 6. Скачиваем данные\n",
    "\n",
    "final_df.to_csv (f'Все дома в городе {city} региона {region}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спасибо за внимание! Если есть какие-то вопросы, я всегда доступна:\n",
    "\n",
    "* Мария Казакова, дата-журналистка\n",
    "* Telegram @oilunem\n",
    "* marikasakowa@gmail.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
